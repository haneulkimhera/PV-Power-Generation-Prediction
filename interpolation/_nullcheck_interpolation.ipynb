{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"17MUjgMrShosv6Gh5kb1m38kurUj-mdV2","authorship_tag":"ABX9TyPzmtpJKit14DA1w7/O06ty"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-q-Uuc8HNjqQ"},"outputs":[],"source":["import pandas as pd\n","from scipy.interpolate import splrep, splev\n","import matplotlib.pyplot as plt\n","import matplotlib.dates as mdates"]},{"cell_type":"code","source":["# Spline Interpolation\n","\n","import matplotlib.pyplot as plt\n","\n","def interpolate_spline(df, column_name):\n","    df.sort_values(by='date', inplace=True)\n","    df.reset_index(drop=True, inplace=True)\n","\n","    df['date'] = pd.to_datetime(df['date'])\n","\n","    # group by date\n","    grouped = df.groupby('date_only')\n","\n","    for date, group in grouped:\n","\n","        # Print information about the group\n","        # print(f\"\\n------ grouped : {date} ------\\n{group}\")\n","\n","        # first case - if it's the first row, take the closest not-nan future value\n","        first_row_index = group.index[0]\n","        # print(f\"\\n- first case - \\n{group.loc[first_row_index, column_name]}\")\n","        # print(f\"\\tfirst case nan check - {group.loc[first_row_index, column_name]}\")\n","        if pd.isna(group.loc[first_row_index, column_name]):\n","            next_non_nan_index = group[column_name].first_valid_index()\n","            # print(f\"\\tnext_non_nan - {next_non_nan_index}\\n{df.loc[next_non_nan_index, column_name]}\")\n","            df.loc[first_row_index, column_name] = df.loc[next_non_nan_index, column_name]\n","            # print(f\"first row index : {first_row_index}, interpolated : {df.loc[first_row_index, column_name]}\")\n","\n","        # second case - if it's the last row, take the closest not-nan past value\n","        last_row_index = group.index[-1]\n","        # print(f\"\\n- last case - \\n\\t{group.loc[last_row_index, column_name]}\")\n","        # print(f\"\\tlast case nan check - {group.loc[last_row_index, column_name]}\")\n","        if pd.isna(group.loc[last_row_index, column_name]):\n","            prev_non_nan_index = group[column_name].last_valid_index()\n","            # print(f\"\\tprev_non_nan - {prev_non_nan_index}\\n{df.loc[prev_non_nan_index, column_name]}\")\n","            df.loc[last_row_index, column_name] = df.loc[prev_non_nan_index, column_name]\n","\n","    # group by date\n","    grouped = df.groupby('date_only')\n","\n","    for date, group in grouped:\n","\n","        # third case - the remaining rows, spline interpolate\n","        non_nan_indices = group.index[~group[column_name].isna()]\n","        spline_x = non_nan_indices.astype(float).values\n","        spline_y = group.loc[non_nan_indices, column_name].values\n","        spline = splrep(spline_x, spline_y, k=3)\n","\n","        nan_indices = group.index[group[column_name].isna()]\n","        # print(f\"nan indices : {nan_indices}\")\n","\n","        if len(nan_indices) > 0:\n","            spline_values = splev(nan_indices.astype(float).values, spline)\n","\n","            # Plot the spline graph\n","            plt.figure()\n","            plt.plot(spline_x, spline_y, 'o', label='Original points')\n","\n","            # Calculate spline curve for more x values\n","            finer_x = np.linspace(spline_x.min(), spline_x.max(), 100)\n","            finer_y = splev(finer_x, spline)\n","\n","            plt.plot(finer_x, finer_y, '-', label='Spline curve')\n","            plt.plot(nan_indices, spline_values, 'x', label='Interpolated values')\n","\n","            plt.title(f\"Spline Interpolation for {column_name} on {date}\")\n","            plt.legend()\n","            plt.show()\n","\n","            # Update the dataframe with interpolated values\n","            df.loc[nan_indices, column_name] = spline_values\n","\n","    print(f\"final df : \\n{df}\")\n","    # return the final df\n","    return df\n"],"metadata":{"id":"D1ZVdgGqyZUV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Linear Interpolation\n","\n","import matplotlib.pyplot as plt\n","\n","def interpolate_linear(df, column_name):\n","  # print(f'original df : {df.shape}')\n","  df.sort_values(by='date', inplace=True)\n","  df.reset_index(drop=True, inplace=True)\n","\n","  # group by date\n","  grouped = df.groupby('date_only')\n","\n","  for date, group in grouped:\n","    # Print information about the group\n","    # print(f\"******** date : {date} ********\")\n","    # print(df[df['date_only']==date])\n","    # print(\"----------------------\")\n","\n","    if group[column_name].isnull().all():\n","      df = df.drop(df[df['date_only'] == date].index)\n","      # print(f\"df after drop :\\n {df.shape}\")\n","      continue\n","\n","    else:\n","      first_row_index = group.index[0]\n","\n","      if pd.isna(group.loc[first_row_index, column_name]):\n","        # print(f\"\\n- first case -\\n\")\n","        # print(f\"\\tfirst case nan check - {group.loc[first_row_index, column_name]}\")\n","        next_non_nan_index = group[column_name].first_valid_index()\n","        # print(f\"\\tnext_non_nan_index - {group.loc[next_non_nan_index, column_name]}\")\n","        df.loc[first_row_index, column_name] = df.loc[next_non_nan_index, column_name]\n","        # print(f\"df after replace :\\n {df[df['date_only']==date]}\")\n","\n","      # second case - if it's the last row, take the closest not-nan past value\n","      last_row_index = group.index[-1]\n","\n","      if pd.isna(group.loc[last_row_index, column_name]):\n","        # print(f\"\\n- second case - \\n\")\n","        # print(f\"\\tsecond case nan check - {group.loc[last_row_index, column_name]}\")\n","        prev_non_nan_index = group[column_name].last_valid_index()\n","\n","        # print(f\"\\tprev_non_nan_index - {group.loc[prev_non_nan_index, column_name]}\")\n","        df.loc[last_row_index, column_name] = df.loc[prev_non_nan_index, column_name]\n","        # print(f\"df after replace :\\n {df[df['date_only']==date]}\")\n","\n","  grouped = df.groupby('date_only')\n","\n","  for date, group in grouped:\n","\n","    # third case - the remaining rows, spline interpolate\n","    nan_indices = group.index[group[column_name].isna()]\n","    non_nan_indices = group.index[~group[column_name].isna()]\n","\n","    if len(nan_indices) > 0:\n","      # print(f\"\\n- third case - \\n\")\n","      # print(f\"\\tthird case nan check - {group.loc[nan_indices, column_name]}\")\n","      df[column_name] = df[column_name].interpolate(method='linear')\n","      # print(f\"df after replace :\\n {df[df['date_only']==date]}\")\n","\n","\n","  # print(f'after {column_name} : {df.shape}')\n","  return df"],"metadata":{"id":"UyDvprAfVVPv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generator_set = [\"samcheonpo\",\"yeongheung\",\"yeongdong\",\"gumi\",\"gwangyanghang\",\"dusan\",\"gyeongsangUni\",\"yecheon\",\"goheungman\"]"],"metadata":{"id":"P5KR0V9zWSFW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# handle columns with more than 40% of none values, and linear interpolate every other.\n","\n","for generator in generator_set:\n","  file_path = '/content/drive/MyDrive/하늘/data files/averaged/'+generator+'.csv'\n","  path = '/content/drive/MyDrive/하늘/data files/nullcheck_interpolated/'+generator+'.csv'\n","  df = pd.read_csv(file_path)\n","  print(f\"***** file : {generator}{df.shape} *****\")\n","\n","  for feature in df.columns:\n","    null_ratio = df[feature].isnull().mean()\n","    # print(f\"{feature} - {null_ratio}\")\n","\n","    if null_ratio > 0.4:\n","        df = df.drop(columns=[feature])\n","        # print(f\"{feature} is dropped. df shape{df.shape}\")\n","\n","  print(f\"\\nafter null check - {df.columns}\\n\")\n","\n","# interpolate missing values using linear interpolation\n","  for feature in df.columns:\n","    linear_df = interpolate_linear(df,feature)\n","    df = linear_df\n","    # print(f\"interpolate {generator}, {df.shape}\")\n","\n","  # print(f\"\\nfor {generator}, final df : {df.shape}\\n\")\n","  df.to_csv(path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xOBv4TzyvsoK","executionInfo":{"status":"ok","timestamp":1701531521755,"user_tz":-540,"elapsed":33927,"user":{"displayName":"김하늘, ITM전공(학부)","userId":"17947900635982434656"}},"outputId":"11666e08-897c-45c0-8b40-f2d6bc9bf08f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["***** file : samcheonpo(7845, 14) *****\n","\n","after null check - Index(['date', 'date_only', 'temperature', 'wind speed', 'humidity',\n","       'air pressure', 'sunshine', 'cloud', 'ground temperature',\n","       'total_weighted_average_power', 'power_plant'],\n","      dtype='object')\n","\n","***** file : yeongheung(7793, 14) *****\n","\n","after null check - Index(['date', 'date_only', 'temperature', 'wind speed', 'humidity',\n","       'air pressure', 'sunshine', 'insolation', 'cloud', 'ground temperature',\n","       'total_weighted_average_power', 'power_plant'],\n","      dtype='object')\n","\n","***** file : yeongdong(7644, 14) *****\n","\n","after null check - Index(['date', 'power_plant', 'total_weighted_average_power', 'date_only',\n","       'temperature', 'wind speed', 'humidity', 'air pressure', 'sunshine',\n","       'insolation', 'cloud', 'ground temperature'],\n","      dtype='object')\n","\n","***** file : gumi(7547, 14) *****\n","\n","after null check - Index(['date', 'power_plant', 'total_weighted_average_power', 'date_only',\n","       'temperature', 'wind speed', 'humidity', 'air pressure', 'sunshine',\n","       'cloud', 'ground temperature'],\n","      dtype='object')\n","\n","***** file : gwangyanghang(7529, 14) *****\n","\n","after null check - Index(['date', 'power_plant', 'total_weighted_average_power', 'date_only',\n","       'temperature', 'wind speed', 'humidity', 'air pressure', 'sunshine',\n","       'insolation', 'cloud', 'ground temperature'],\n","      dtype='object')\n","\n","***** file : dusan(7516, 14) *****\n","\n","after null check - Index(['date', 'power_plant', 'total_weighted_average_power', 'date_only',\n","       'temperature', 'wind speed', 'humidity', 'air pressure', 'sunshine',\n","       'insolation', 'cloud', 'ground temperature'],\n","      dtype='object')\n","\n","***** file : gyeongsangUni(7330, 14) *****\n","\n","after null check - Index(['date', 'power_plant', 'total_weighted_average_power', 'date_only',\n","       'temperature', 'wind speed', 'humidity', 'air pressure', 'sunshine',\n","       'insolation', 'cloud', 'ground temperature'],\n","      dtype='object')\n","\n","***** file : yecheon(7096, 14) *****\n","\n","after null check - Index(['date', 'power_plant', 'total_weighted_average_power', 'date_only',\n","       'temperature', 'wind speed', 'humidity', 'air pressure', 'sunshine',\n","       'cloud', 'ground temperature'],\n","      dtype='object')\n","\n","***** file : goheungman(665, 14) *****\n","\n","after null check - Index(['date', 'power_plant', 'total_weighted_average_power', 'date_only',\n","       'temperature', 'wind speed', 'humidity', 'air pressure', 'sunshine',\n","       'cloud', 'ground temperature'],\n","      dtype='object')\n","\n"]}]},{"cell_type":"code","source":["# check if any null value is left\n","\n","for generator in generator_set:\n","  path = '/content/drive/MyDrive/하늘/data files/nullcheck_interpolated/'+generator+'.csv'\n","  df = pd.read_csv(path)\n","  # print(df.isnull().any())\n","  # print(df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9SDbBooX4O7W","executionInfo":{"status":"ok","timestamp":1700805079942,"user_tz":-540,"elapsed":1012,"user":{"displayName":"김하늘, ITM전공(학부)","userId":"17947900635982434656"}},"outputId":"f3e2e295-dd21-49cc-8908-ce42999eb160"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(7779, 13)\n","(7779, 13)\n","(7644, 13)\n","(7547, 12)\n","(7529, 13)\n","(7516, 13)\n","(7330, 13)\n","(7096, 12)\n","(665, 12)\n"]}]}]}